<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>
      Márton Münz, PhD | Computational Biology & Cloud Computing Consultant
    </title>
    <link
      href="https://fonts.googleapis.com/css2?family=Clash+Display:wght@600;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
        margin: 0;
        padding: 0;
        background: #f8f9fa;
        color: #1a1a1a;
      }
      header {
        background: #c6e3f6;

        backdrop-filter: blur(10px);

        padding: 3rem 1rem 2rem;

        text-align: center;

        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);

        position: relative;
      }

      header h1 {
        margin: 0 0 0.5rem;

        font-size: 3rem;

        font-family: "Clash Display", "Helvetica Neue", Helvetica, Arial,
          sans-serif;

        font-weight: 700;

        color: #5c5f66;
      }

      header p {
        margin: 0.5rem 0 1.5rem;

        font-size: 1.2rem;

        color: #1a1a1a;
      }

      .header-links {
        display: flex;

        justify-content: center;

        gap: 1.5rem;

        margin-top: 1rem;
      }

      .header-links a {
        color: #146c60;

        text-decoration: none;

        font-size: 1.2rem;

        display: flex;

        align-items: center;

        gap: 0.5rem;
      }

      .header-links img {
        width: 20px;

        height: 20px;
      }
      section {
        padding: 2rem 2rem;
        max-width: 900px;
        margin: auto;
        background: #c6e3f6;
        margin-top: 2rem;
        border-radius: 12px;
        box-shadow: 0 2px 15px rgba(0, 0, 0, 0.3);
        text-align: center;
      }
      section h2 {
        color: #5c5f66;
        font-size: 2rem;
        margin-bottom: 1.5rem;
        text-align: left;
      }

      section p {
        text-align: left;
        font-size: 1.2rem;
      }

      b {
        color: #c6e3f6;
      }

      ul {
        list-style-type: none;
        padding: 0;
        text-align: left;
      }
      li {
        margin: 0.8rem 0;
        font-size: 1.2rem;
      }
      .highlight {
        color: #2541b2;
        font-weight: bold;
      }
      .cta {
        display: none;
      }
      .button-link {
        background: #146c60;
        color: #c6e3f6;
        padding: 1rem 2rem;
        text-decoration: none;
        border-radius: 8px;
        font-size: 1.5rem;
        transition: background 0.3s ease;
        display: inline-block;
        margin-top: 1.5rem;
        border: 1px solid rgba(255, 255, 255, 0.1);
      }
      .button-link:hover {
        background: #e4f2ee;
        color: #1a1a1a;
        text-align: left;
      }
      footer {
        text-align: center;
        font-size: 1.2rem;
        padding: 2rem 1rem;
        color: rgba(9, 9, 9, 0.6);
      }
      a:not(header a) {
        color: #146c60;
        text-decoration: underline;
        font-size: 1.2rem;
        text-align: left;
      }
      header a {
        text-decoration: none;
      }
      h3 {
        margin-top: 2rem;
        text-align: left;
        font-size: 1.4rem;
      }
    </style>
  </head>
  <body>
    <header>
      <a href="index.html">
        <h1>Márton Münz, PhD</h1>
        <p>Computational Biology | Cloud Infrastructure | AI Consulting</p>
        <div class="header-links">
          <a href="mailto:hello@martonmunz.com">
            <img
              src="https://img.icons8.com/?size=100&id=eKlyMs0XteXZ&format=png&color=000000"
              alt="Email"
            />Email
          </a>
          <a href="https://www.linkedin.com/in/marton-munz-phd" target="_blank">
            <img
              src="https://img.icons8.com/?size=100&id=13930&format=png&color=000000"
              alt="LinkedIn"
            />LinkedIn
          </a>
        </div>
      </a>
    </header>

    <section>
      <h2>AI-powered data workflows in Biotech</h2>

      <p>
        A promising frontier in biotech research is the use of Large Language
        Models (LLMs) and LLM-based agents that directly interact with internal
        infrastructure — i.e. have the ability to query databases, trigger
        computational workflows, and dynamically interact with in-house data
        pipelines. These AI tools will transform how researchers access and
        manage complex bioinformatics systems, enabling natural language
        commands to replace manual scripting or GUIs, boosting everyday
        productivity. In addition, the ability to use natural language to drive
        complex operations can reduce the overhead of managing fragmented data
        and compute ecosystems.
      </p>
      <p>
        More crucially, LLM-based workflows and agents take automation to the
        next level. Thanks to their reasoning abilities and tool use, with
        access to both internal (structured or unstructured) data and external
        APIs, they are able to decompose complex tasks into manageable steps and
        carry them out autonomously. This opens the door to fully autonomous
        research assistants that can, for instance, monitor new data arrivals,
        preprocess raw datasets, identify and execute relevant analysis
        pipelines, interpret the results, and even generate preliminary reports
        or visualizations — all without human intervention.
      </p>
      <p>
        LLM-driven automation isn't just about speeding up existing tasks; it's
        about redefining how research is conducted.
      </p>
      <p>
        Complete autonomy of these AI agents is likely not ideal in domains like
        biotech and bioinformatics, so building human-in-the-loop systems is
        essential. By embedding human oversight into the system, it is possible
        to combine the speed and scalability of LLM-based agents with the domain
        expertise and critical judgment of scientists.
      </p>
      <h3>Examples of integrating LLMs into Biotech workflows</h3>

      <p>
        <span class="highlight"
          >1. RAG systems with access to internal SOPs / Guidelines /
          Protocols</span
        >: To the question by a lab technician
        <i
          >“How do I run a maintenance wash on the Illumina MiSeq before a
          600-cycle v3 kit?”</i
        >, the LLM agent would respond with the correct procedure as described
        in the relevant in-house SOP document.
      </p>
      <p>
        <span class="highlight"
          >2. Querying internal omics (meta)data using natural language</span
        >: Instead of learning SQL or Cypher, a researcher could just ask,
        <i
          >“Show me all in-house RNA-seq experiments from liver tissues in mouse
          models of NASH”</i
        >. The LLM agent would translate it into the appropriate query and
        return the results.
      </p>

      <p>
        <span class="highlight"
          >3. Research questions combining internal and external data</span
        >: To the question
        <i
          >“Can you find publications about colorectal cancer that discuss genes
          found to be differentially expressed in our in-house assays?”</i
        >, the LLM agent would return relevant results from its knowledge graph
        integrating in house datasets with public data fetched via APIs.
      </p>

      <p>
        <span class="highlight">4. Data management</span>:
        <i
          >"Give our bioinformatician, John Doe access to the RNA-seq dataset
          RNASeq_ASSAY_1, excluding Samples 1 to 6."</i
        >
        The LLM agent will modify the underlying AWS IAM policy to give a user
        permission to access an S3 bucket folder, excluding the specified
        subfolders. Data access control is therefore as simple as issuing a
        natural language instruction, shielding users from the complexity of AWS
        policy syntax and reducing the risk of misconfiguration.
      </p>

      <p>
        <span class="highlight"
          >5. Provisioning/configuring cloud resources</span
        >:
        <i
          >"Launch a t2.large EC2 instance with a new EFS file system mounted.
          Switch the EFS to Elasatic Throughput mode."
        </i>
        The agent modifies the AWS infrastructure as requested.
      </p>

      <p>
        <span class="highlight"
          >6. Calling bioinformatics pipelines and interpreting results</span
        >: An LLM agent that has access to an RNA-seq Differential Gene
        Expression analysis pipeline and the Open Targets API would be able to
        answer the question:
        <i
          >"Identify potential drug targets for Parkinson's disease by
          cross-referencing overexpressed genes (p-adj < 0.05 and logFC ≥ 1)
          from our in-house datasets with known gene-disease associations and
          druggability information from the Open Targets database."</i
        >
        Note that this is different from 3. where the agent has the list of
        differentially expressed genes readily available in its knowledge base,
        while here the agent itself executes the bioinformatics pipeline to
        derive these genes.
      </p>

      <p>
        <span class="highlight">7. Controlling multi-step workflows</span>:
        <i
          >“Rerun the QC analysis of the sequencing run
          240508_NB552789_0123_AH5C7KBGX3 after switching the adapter trimming
          strategy from a fixed 10 bp trim to dynamic trimming. If the mapping
          rate is normal, carry on with variant calling, but send me a Slack
          alert if not. Email me a full QC report at the end."</i
        >
        The agent controls the flow of a data analysis pipeline implemented in
        AWS Step Functions.
      </p>

      <p>
        <span class="highlight">8. Complex research queries</span>:
        <i
          >"Using publicly available gene expression and clinical outcome data
          and relevant publications not older than 5 years, can you identify
          novel biomarkers for drug resistance in triple-negative breast cancer,
          and propose a mechanism by which they mediate resistance?"</i
        >
        To generate an answer to this request, an LLM agent will need to check
        multiple data sources (e.g. GEO, TCGA, cBioPortal, PubMed), reason
        across diverse types of information, and synthesize its findings into a
        coherent hypothesis.
      </p>

      <h3>Key implementation challanges</h3>

      <p>
        Although adding LLMs and LLM-based agents to biotech workflows holds
        great potential, their implementation presents some challenges:
      </p>

      <p>
        - <span class="highlight">Data Security</span>: Using LLM API endpoints
        like those of OpenAI or Anthropic (Claude) means that all prompts and
        queries — including proprietary data from a biotech company — are sent
        to and processed on external third-party servers, raising concerns about
        data confidentiality and compliance. While OpenAI, for example, claims
        not to use these data for training their models, some companies remain
        wary, especially in highly regulated environments such as
        pharmaceuticals or genomics, where any data exposure could lead to
        serious legal or competitive consequences. One solution is to avoid
        sending sensitive data to third-party APIs altogether by using a secure,
        local or cloud-based deployment of open source LLM models with the
        inference running on on-premises or VPC-isolated cloud servers. LLM
        inference, however, demands powerful GPUs to handle the intensive
        computation required for executing the model with low latency.
      </p>

      <p>
        - <span class="highlight">Customization</span>: General-purpose LLM
        chatbots like ChatGPT, especially when equipped with web search
        capabilities, are powerful tools for research. However, they lack access
        to internal data and infrastructure. Customizing LLM-based systems
        requires integrating them with internal data sources, defining the tools
        they can use to interact with in-house infrastructure, outlining their
        operational logic and workflows, specifying their level of autonomy, and
        the way they engage with users. Systems can differ significantly in
        these implementation details, depending on the specific use cases they
        are optimized for.
      </p>

      <h3>What I offer</h3>

      <p>
        I design and develop custom solutions for integrating LLM-based systems
        into your biotech workflows, tailored to your specific data,
        infrastructure, and use cases — from straightforward RAG implementations
        to complex agentic workflows. This includes deploying private LLM
        models, either on-premise or in secure, isolated cloud environments, to
        ensure full data confidentiality and compliance. We will work closely to
        define a custom system that fits your use case and aligns with your
        research goals and data security requirements.
      </p>

      <br />

      <a href="index.html">← Back to Main Page</a>
    </section>

    <footer>
      <p>© 2025 Márton Münz</p>
    </footer>
  </body>
</html>
